{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy.stats as stats\n",
    "# from statsmodels.stats import proportion as proptests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data: size (84534, 10)\n",
      "Loaded testing data: size (41650, 10)\n",
      "----------------\n",
      "train_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044331</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044331 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/training.csv')\n",
    "print('Loaded training data: size {}'.format(train_df.shape))\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "print('Loaded testing data: size {}'.format(test_df.shape))\n",
    "print('----------------')\n",
    "print('train_df:')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate number of customers and purchasers in treatment and control group\n",
    "\n",
    "* `Treatment` group: received promotion, need to test the effect of promotion program in this group\n",
    "* `Control` group: NOT received promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total customers: 84534\n",
      "Number of customers in treatment group: 42364\n",
      "Number of customers in control group: 42170\n",
      "Number of purchasers in treatment group: 721\n",
      "Number of purchasers in control group: 319\n"
     ]
    }
   ],
   "source": [
    "totalCustomer = train_df.shape[0]\n",
    "numberCustomerTreatment = train_df['Promotion'].value_counts()[0]\n",
    "numberCustomerControl = train_df['Promotion'].value_counts()[1]\n",
    "numberPurchaserTreatment = train_df.groupby('Promotion')['purchase'].sum()[1]\n",
    "numberPurchaserControl = train_df.groupby('Promotion')['purchase'].sum()[0]\n",
    "\n",
    "print('Total customers: {}'.format(totalCustomer))\n",
    "print('Number of customers in treatment group: {}'.format(numberCustomerTreatment))\n",
    "print('Number of customers in control group: {}'.format(numberCustomerControl))\n",
    "print('Number of purchasers in treatment group: {}'.format(numberPurchaserTreatment))\n",
    "print('Number of purchasers in control group: {}'.format(numberPurchaserControl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate IRR and NIR\n",
    "\n",
    "`IRR (Incremental Response Rate)` depicts how many more customers purchased the product with the promotion, as compared to if they didn't receive the promotion.\n",
    "\n",
    "$$ IRR = \\frac{purchasers_{treatment}}{customers_{treatment}} - \\frac{purchasers_{control}}{customers_{control}} $$\n",
    "\n",
    "\n",
    "`NIR (Net Incremental Revenue)` depicts how much is made (or lost) by sending out the promotion\n",
    "\n",
    "$$ NIR = (10\\cdot purchasers_{treatment} - 0.15 \\cdot customers_{treatment}) - 10 \\cdot purchasers_{control}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRR = 0.009454547819772702\n",
      "NIR = -2334.5999999999995\n"
     ]
    }
   ],
   "source": [
    "IRR = (numberPurchaserTreatment/numberCustomerTreatment) - (numberPurchaserControl/numberCustomerControl)\n",
    "print('IRR = {}'.format(IRR))\n",
    "\n",
    "NIR = (10*numberPurchaserTreatment - 0.15*numberCustomerTreatment) - 10*numberPurchaserControl\n",
    "print('NIR = {}'.format(NIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. State and test hypothesis\n",
    "\n",
    "`Permutation test` method is used to test hypotheses.\n",
    "\n",
    "The permutation test is a resampling-type test used to compare the values on an outcome variable between two or more groups. In the case of the permutation test, resampling is done on the group labels. The idea here is that, under the null hypothesis, the outcome distribution should be the same for all groups, whether control or experimental. Thus, we can emulate the null by taking all of the data values as a single large group. Applying labels randomly to the data points (while maintaining the original group membership ratios) gives us one simulated outcome from the null.\n",
    "\n",
    "The rest follows similar to the sampling approach to a standard hypothesis test, except that we haven't specified a reference distribution to sample from â€“ we're sampling directly from the data we've collected. After applying the labels randomly to all the data and recording the outcome statistic many times, we compare our actual, observed statistic against the simulated statistics. A p-value is obtained by seeing how many simulated statistic values are as or more extreme as the one actually observed, and a conclusion is then drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Hypothesis 1\n",
    "\n",
    "* H0: $numberCustomerTreatment = numberCustomerControl$\n",
    "* Ha: $numberCustomerTreatment \\ne numberCustomerControl$\n",
    "\n",
    "$\\alpha$ = 0.05 (significance level)\n",
    "\n",
    "This hypothesis is to test whether the difference between number of customers in treatment group and control group is statistically significant. If it's statistical significant, this will require us to revise random assignment procedures and re-do data collection. The ultimate purpose is to make sure our inferences on the desired metrics are not founded on bias due to sampling population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Test hypothesis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5034"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = int(round(train_df.shape[0] * 0.2,0)) #get 20% of the population as sample\n",
    "\n",
    "sample_differences = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    \n",
    "    sub_sample = train_df.sample(sample_size, replace=True)\n",
    "    treatment_ratio = ((sub_sample.Promotion == \"Yes\").sum())/sub_sample.shape[0]\n",
    "    control_ratio = (sub_sample.Promotion == \"No\").sum()/sub_sample.shape[0]\n",
    "    sample_differences.append(treatment_ratio - control_ratio)\n",
    "\n",
    "observe_difference = numberCustomerTreatment/totalCustomer - numberCustomerControl/totalCustomer\n",
    "\n",
    "# Determining the signifigance of our result \n",
    "p_val = (sample_differences > observe_difference).mean()\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `p_value = 0.5034` > $\\alpha$ = 0.05, not enough evidence to reject null hypothesis. That means there's no statistical difference in the sampling population. We can rely on this the sampling population for further inferential analysis with desired metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Hypothesis 2\n",
    "\n",
    "* H0: Incremental Response Rate  = 0\n",
    "* Ha: Incremental Response Rate > 0\n",
    "\n",
    "$\\alpha$ = 0.05 (significance level)\n",
    "\n",
    "This hypothesis is to test whether the promotion program had a positive effect on `IRR` metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Test hypothesis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.9458\n"
     ]
    }
   ],
   "source": [
    "sample_size = int(round(train_df.shape[0] * 0.2,0)) #get 20% of the population as sample\n",
    "\n",
    "sample_differences = []\n",
    "\n",
    "n_trials = 10000\n",
    "\n",
    "for _ in range(n_trials):\n",
    "    \n",
    "    sub_sample = train_df.sample(sample_size, replace=True)\n",
    "\n",
    "    purchase_treatment = sub_sample[sub_sample['Promotion'] == \"Yes\"].purchase.sum()\n",
    "    customer_treatment = sub_sample[sub_sample['Promotion'] == \"Yes\"].shape[0]\n",
    "    purchase_control = sub_sample[sub_sample['Promotion'] == \"No\"].purchase.sum()\n",
    "    customer_control = sub_sample[sub_sample['Promotion'] == \"No\"].shape[0]\n",
    "\n",
    "    sample_IRR = purchase_treatment/customer_treatment - purchase_control/customer_control\n",
    "\n",
    "    sample_differences.append(sample_IRR)\n",
    "\n",
    "p_null = np.random.normal(sum(sample_differences)/sample_size, np.std(sample_differences), n_trials)\n",
    "\n",
    "# Determining the signifigance of our result \n",
    "p_val = (sample_differences > p_null).mean()\n",
    "print('p_value: {}'.format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p_value` = 0.9458 > $\\alpha$ = 0.05 which means p_value is above null distribution. Therefore the null hypothesis is rejected. There is a statistical increase in IRR when the customers received promotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Hypothesis 3\n",
    "\n",
    "* H0: Net Incremental Revenue = 0\n",
    "* Ha: Net Incremental Revenue > 0\n",
    "\n",
    "$\\alpha$ = 0.05 (significance level)\n",
    "\n",
    "This hypothesis is to test whether the promotion program had a positive effect on `NIR` metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Test hypothesis 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.0123\n"
     ]
    }
   ],
   "source": [
    "sample_size = int(round(train_df.shape[0] * 0.2,0)) #get 20% of the population as sample\n",
    "\n",
    "sample_differences = []\n",
    "\n",
    "n_trials = 10000\n",
    "\n",
    "for _ in range(n_trials):\n",
    "    \n",
    "    sub_sample = train_df.sample(sample_size, replace=True)\n",
    "\n",
    "    purchase_treatment = sub_sample[sub_sample['Promotion'] == \"Yes\"].purchase.sum()\n",
    "    customer_treatment = sub_sample[sub_sample['Promotion'] == \"Yes\"].shape[0]\n",
    "    purchase_control = sub_sample[sub_sample['Promotion'] == \"No\"].purchase.sum()\n",
    "    customer_control = sub_sample[sub_sample['Promotion'] == \"No\"].shape[0]\n",
    "\n",
    "    sample_NIR = (10*purchase_treatment - 0.15*customer_treatment) - 10*purchase_control\n",
    "\n",
    "    sample_differences.append(sample_NIR)\n",
    "\n",
    "p_null = np.random.normal(0, np.std(sample_differences), 10000)\n",
    "\n",
    "# Determining the signifigance of our result \n",
    "p_val = (sample_differences > p_null).mean()\n",
    "print('p_value: {}'.format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p_value` = 0.0123 < $\\alpha$ = 0.05 which means p_value is below null distribution, it's still in the confidence interval. Therefore, there's not enough evidence to reject the null hypothesis. There's no effect on NIR metric when the customers received promotion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
